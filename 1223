1. 課題
影響調査の作業とシステムの全体像理解を並行して、限られた時間で完了させる必要がある。

・初めて扱うシステムで、開発経験も豊富ではないため、短時間で影響調査を完了させることが難しい。 （以前のPJではテスト作業に追われ、十分なシステム理解ができなかった。）
(・本機能のドキュメントはほとんどなかった。)
→ 限られた時間で効率的にシステムを理解するため、AIを活用してシステム全体像の理解に努めた。

具体：生成AI活用開発フレームワーク および M365Copilot を使用した設計書、フロー図の作成

Input：自分の担当する機能のソースコード

Output：システム構成図、フロー図、詳細設計書

短時間で影響調査を完了させることが難しい。

→ 一般的な影響調査の方法を担当者に学びつつ、AIを使って汎用的な影響調査のやり方を検討。

→ 限られた時間で効率的かつ品質を担保した影響調査のやり方として、ABC案を考え評価した。

ABC案の比較
A案：
過去のプロジェクトや標準手順に基づくある程度確立されたやり方

メリット：再現性が高く、レビューでの信頼性がある。
デメリット：時間がかかる。初見システムでは理解に時間を要する。
B案：
従来の手順をベースに、AIを補助的に使って効率化。

メリット：時間短縮＋品質担保（人のチェックあり）、初見システムでもキャッチアップが早い。
デメリット：AIの回答妥当性評価にスキルが必要、網羅性や再現性確保の工夫が必要。
C案：
AIに大部分を任せ、人はレビューと最終判断のみ。

メリット：スピードが最も速い。
デメリット：AIの誤りリスクが高い、根拠の説明やレビュー効率に課題（情報過多や不明確な箇所）。
→ メリット・デメリット(時間、品質、実効可能か)を比較し、評価した結果、B案を採用して進めることにした。

2. 具体的な対策方法
案1：システム理解をAIで効率化
AIを活用して、システム全体像を理解する手助けをさせた。 （開発フレームワークを使ってシステム構成図、フロー図、詳細設計書作成）
案2：影響調査作業をAIで効率化
「影響調査」の特にコンパイルエラー調査を対象とする。
「影響調査」工程の一次調査をAIに任せ、自分で精密チェック。
調査結果の妥当性を自分とAIでダブルチェック。


3. AI活用の課題（B案採用後）
AIは回答に網羅性がない。
AIの回答妥当性評価が自分だけのスキルでは難しい。
工夫：
AIの作成物や影響調査の方法に対して、どのように評価・補完したか。

AIに「どのファイル・どの行を根拠にしたか」を出力。
自分自身もコードを確認し、公式ドキュメント等も確認。
有識者に最終チェックをいただく。

コンパイルエラー調査内容（AIを取り入れていない場合)
1.Java11環境でソースコードをコンパイル
2.コンパイルエラーの内容を目視で読み解き、原因を推定
3.Web検索や技術書、既存の設計書を調査し、自力で修正方法を特定する
4.公式リファレンス等で裏付けを行い、間違いがないか確認する

コンパイルエラー調査内容(AIを取り入れた場合)
1.Java11環境でソースコードをコンパイル
2.コンパイルエラーの原因と修正方法をAIで１次調査させる
（※この際、推論の根拠となる「ファイル名・行番号」を必ず出力させる）
3.AIが提示した根拠を元に、自身で実際のコードと公式ドキュメントを確認し、間違いがないか確認する
4.修正方針について有識者に最終チェック（レビュー）を依頼し、品質を担保する

4. 成果
調査対象コード行数：2,224 steps
コンパイルエラー原因特定の精度：AI＋人のダブルチェックでレビュー時の指摘は1件に抑えた。
「影響調査工程」の作業を順調に進め、最初のレビューまでに一通りの調査を完了。

5. 課題その2
課題の内容
調査結果や判断根拠をレビューで説明する際、情報が整理されておらず、時間が不足した。 AI活用により情報量は増えたが、逆に「どこを見ればよいかわからない」状態を生んだ。

背景要因
PJ内に技術経験者が不在で、外部有識者に頼るしかない状況。
成果物の期限、システム理解のキャッチアップ、少ないレビュー機会を無駄にできないというプレッシャー。
過去に根拠資料不足で再レビューとなり、レビューが何往復もした経験があった。

6. 分析
試行結果
「情報不足で答えられないことを避けたい」という思いから、調査結果をすべて準備して臨んだ。
AI活用により「情報不足はないはず」という安心感があったが、逆に「どこを見ればよいかわからない」状態になり、レビュー効率を低下させた。
分析
情報過多は「相手の判断コスト」を増加させる。
必要なのは「相手目線で論点を整理」すること。

構成イメージ（ピラミッド図）：
底層： コンパイルエラーログ、ソースコード（膨大・AIが得意）
→ ここをそのまま見せて失敗した。
中層： エラーの分類、発生箇所の特定（整理）
→ ここまではAIもできる。
頂点： 「このエラーは修正による影響リスクが低い」という判断（人間がやるべきこと）
→ レビューに必要なのはここだけ。

7. 具体的な対策
「全ての情報を伝える」のではなく、レビュアーが意思決定に必要な順序で情報を構成し、
「結論（頂点）」から伝えつつ、必要に応じて「根拠（中層・底層）」へ即座にアクセスできるようにした。

・まずは「結論」だけを見せる：いきなり全部を説明せず、冒頭で「今回の重要なポイント」と「自分の判断」だけを伝え、相手が見るべき場所を絞り込んだ。
・グループ分けして整理し、すぐに見せる準備： エラーをただ並べるのではなく、今回の目的である「Java11化において重要かどうか」という視点でグループ分けして整理した。 もし「根拠は？」と聞かれたら、あらかじめ用意しておいた根拠や調査方法の説明をすぐに出せるようにし、説明の早さと安心感を両立させた。

8. 成果と学び
成果
スケジュールの遵守： 手戻りがなくなったことで、限られた期間内での調査を完了し、遅延なく次工程へ進むことができた。
有識者から 「そこまで調べているならその判断で大丈夫」 と信頼を得て、レビュー1回で通過。

学び
・「準備」の定義が変わった： 準備とは、不安を埋めるために情報を集めることではなく、「相手が最短で意思決定できるように情報を整理すること」だと学んだ。
・AIと人間の役割分担： 「データ収集・一次整理」はAIに任せられるが、最終的な「価値判断」を行い、責任を持つのは人間であると実感した。


「詳細設計」「コーディング」工程で生じた課題と対策
1. 課題
現在のリスク： 「自分だけの思い込み」で進んでしまう懸念。コードが動いているとしても、「正しいプロセスや考慮を経て作られたか」を客観的に証明できない状態だった。
未来のリスク： 成果物だけでは「なぜA案ではなくB案を選んだか」という背景が見えない。「動けばいい」だけの修正は、将来的に修正意図が不明になり、未来の自分や後任者を苦しめる可能性があった。

背景要因
実作業担当者が私一人だけという体制で、相談の機会も限られているため、日々の細かい技術判断は自分自身に委ねられてた。

具体：詳細設計の際、自分では「これで十分伝わる」と確信して書いた記述に対し、有識者から「これでは後から見た人が文脈を理解できない」と指摘を受けた。 そこで初めて、自分が「自分の頭の中にしかない前提知識」に頼って、自分勝手な解釈で作業を進めていたことに気づかされた。

2. 分析
客観性の確保： 指摘を受けるまで、私は自分の頭の中にある「前提知識」や「感覚」という暗黙知に頼って作業をしていた。自分の感覚で判断するのではなく、「プロジェクトのルール（品質基準）」という客観的な物差しを使って、機械的に合否を決めるべきだと考えた。
透明性の確保：最終的なコード（結果）は目に見えるが、「どのような検索ワードで調べ、どの資料を根拠とし、どう検証したか」という「調査プロセス」は暗黙知のまま消えてしまう。自分の作業の透明性を高めるために成果物に「正解」だけでなく「なぜそれを選んだか」を残し、誰が見ても納得できる状態にする。

具体例：詳細設計書作成の際、影響調査フェーズの結果を記述するときに「具体的にどういう方法でどんな検索キーワードでその情報に辿り着いたのか？ その『探し方』も含めて残さないと、第三者が検証できない」という指摘をいただいた。

3. 対策
・品質基準の「自分ごと化」推進：「言われたからやる」のではなく、プロジェクトの標準品質基準を自ら調査し、その基準を満たすため、必要な有識者の選定から日程調整までを自ら推進してレビューを開催し、品質担保の場を能動的に作った。
・成果物そのもの（設計書やコード）に「なぜそうしたか」という思考プロセスを直接記述する。
　→レビュー資料は「承認をもらったら終わり」だが、これは「システムの寿命が続く限り残る資産」として、検討経緯を明記した
　詳細設計書：思考プロセスを明記
　コーディング：コメントを追記
　
4. 結果
各工程で品質基準を満たした資料を作成することができた。
